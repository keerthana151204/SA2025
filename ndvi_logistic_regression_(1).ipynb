{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cf821c0d",
      "metadata": {
        "id": "cf821c0d"
      },
      "source": [
        "# NDVI-based Land Cover Classification\n",
        "Improved logistic regression model using feature engineering and denoising."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f147b88a",
      "metadata": {
        "id": "f147b88a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1567115f",
      "metadata": {
        "id": "1567115f"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_df = pd.read_csv(\"/kaggle/input/summer-analytics-mid-hackathon/hacktrain.csv\")\n",
        "test_df = pd.read_csv(\"/kaggle/input/summer-analytics-mid-hackathon/hacktest.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb4cfc7d",
      "metadata": {
        "id": "bb4cfc7d"
      },
      "outputs": [],
      "source": [
        "ndvi_columns = [col for col in train_df.columns if '_N' in col]\n",
        "X_train_raw = train_df[ndvi_columns]\n",
        "y_train_raw = train_df['class']\n",
        "X_test_raw = test_df[ndvi_columns]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train_raw)\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train_raw), columns=ndvi_columns)\n",
        "X_test_imputed = pd.DataFrame(imputer.transform(X_test_raw), columns=ndvi_columns)\n",
        "\n",
        "def extract_features(df):\n",
        "    base = df.copy()\n",
        "    base['ndvi_mean'] = base.mean(axis=1)\n",
        "    base['ndvi_std'] = base.std(axis=1)\n",
        "    base['ndvi_min'] = base.min(axis=1)\n",
        "    base['ndvi_max'] = base.max(axis=1)\n",
        "    base['ndvi_range'] = base['ndvi_max'] - base['ndvi_min']\n",
        "    base['ndvi_early_avg'] = base.iloc[:, -10:].mean(axis=1)\n",
        "    base['ndvi_late_avg'] = base.iloc[:, :10].mean(axis=1)\n",
        "    base['ndvi_seasonal_diff'] = base['ndvi_late_avg'] - base['ndvi_early_avg']\n",
        "    return base\n",
        "\n",
        "X_train_features = extract_features(X_train_imputed)\n",
        "X_test_features = extract_features(X_test_imputed)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_features)\n",
        "X_test_scaled = scaler.transform(X_test_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f38926b3",
      "metadata": {
        "id": "f38926b3"
      },
      "outputs": [],
      "source": [
        "clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
        "clf.fit(X_train_scaled, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb142011",
      "metadata": {
        "id": "eb142011"
      },
      "outputs": [],
      "source": [
        "y_test_pred = clf.predict(X_test_scaled)\n",
        "y_test_labels = le.inverse_transform(y_test_pred)\n",
        "\n",
        "submission = pd.DataFrame({'ID': test_df['ID'], 'class': y_test_labels})\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}